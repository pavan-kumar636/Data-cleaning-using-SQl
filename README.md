# Data-cleaning-using-SQl
This project describes about the process or the techniques that are involved in the data cleaning.

Data cleaning is a crucial step in data analysis and machine learning. It involves identifying and correcting errors, inconsistencies, and inaccuracies in a dataset.
SQL, a powerful language for managing and manipulating data, can be effectively used for data cleaning tasks.

In this Project I have worked on Layoffs dataset. Which has more null values, missing values, duplicates, unnecessary data, inconsistencies. That's why I have cleaned it.

The process I have used in this project is :
1. Removing duplicates
   To remove duplicate rows from a table, we typically identify the duplicate rows and then delete the unwanted ones. Here are the common methods:
   - Using ROW_NUMBER() Function
   - Using DISTINCT keyword

2. Standardize the data
   Data standardization is a crucial step in data preprocessing, particularly for machine learning and data analysis. It involves transforming data into a common format to ensure
   consistency and comparability across different datasets.

3. Handling Missing values and Null values
   Missing values and null values are common challenges in data analysis and machine learning. They can significantly impact the quality and accuracy of your models

4. Removing unnecessary columns
   Removing unnecessary columns can:
   Improve Query Performance: Fewer columns to process mean faster query execution.
   Reduce Storage Space: Less data to store means lower storage costs.


